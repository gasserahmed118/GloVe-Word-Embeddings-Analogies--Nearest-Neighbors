{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ed2eaf",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dd24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from future.utils import iteritems\n",
    "from builtins import range\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea523f97",
   "metadata": {},
   "source": [
    "# Distance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711c341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance\n",
    "def dist1(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "# Cosine distance\n",
    "def dist2(a, b):\n",
    "    return 1 - a.dot(b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cc418",
   "metadata": {},
   "source": [
    "# Distance Metric Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f299201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose distance function\n",
    "dist, metric = dist2, 'cosine'\n",
    "# dist, metric = dist1, 'euclidean'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec877e",
   "metadata": {},
   "source": [
    "# Analogy Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9656d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogies(w1, w2, w3):\n",
    "    \"\"\"\n",
    "    Solves analogies of the form:\n",
    "    w1 - w2 + w3 ≈ ?\n",
    "    Example: king - man + woman ≈ queen\n",
    "    \"\"\"\n",
    "\n",
    "    for w in (w1, w2, w3):\n",
    "        if w not in word2vec:\n",
    "            print(\"%s not in dictionary\" % w)\n",
    "            return\n",
    "\n",
    "    v0 = word2vec[w1] - word2vec[w2] + word2vec[w3]\n",
    "\n",
    "    min_dist = float('inf')\n",
    "    best_word = None\n",
    "\n",
    "    for word, v1 in iteritems(word2vec):\n",
    "        if word not in (w1, w2, w3):\n",
    "            d = dist(v0, v1)\n",
    "            if d < min_dist:\n",
    "                min_dist = d\n",
    "                best_word = word\n",
    "\n",
    "    print(w1, \"-\", w2, \"=\", best_word, \"-\", w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1240fe3f",
   "metadata": {},
   "source": [
    "# Optimized Analogy Solver (Vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c716a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogies_fast(w1, w2, w3):\n",
    "    \"\"\"\n",
    "    Faster analogy computation using pairwise distances\n",
    "    \"\"\"\n",
    "\n",
    "    for w in (w1, w2, w3):\n",
    "        if w not in word2vec:\n",
    "            print(\"%s not in dictionary\" % w)\n",
    "            return\n",
    "\n",
    "    v0 = word2vec[w1] - word2vec[w2] + word2vec[w3]\n",
    "\n",
    "    distances = pairwise_distances(\n",
    "        v0.reshape(1, D),\n",
    "        embedding,\n",
    "        metric=metric\n",
    "    ).reshape(V)\n",
    "\n",
    "    idxs = distances.argsort()[:4]\n",
    "\n",
    "    for idx in idxs:\n",
    "        word = idx2word[idx]\n",
    "        if word not in (w1, w2, w3):\n",
    "            print(w1, \"-\", w2, \"=\", word, \"-\", w3)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b622e557",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75cdd8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(w, n=5):\n",
    "    \"\"\"\n",
    "    Prints the n nearest neighbors of a word\n",
    "    \"\"\"\n",
    "\n",
    "    if w not in word2vec:\n",
    "        print(\"%s not in dictionary\" % w)\n",
    "        return\n",
    "\n",
    "    v = word2vec[w]\n",
    "\n",
    "    distances = pairwise_distances(\n",
    "        v.reshape(1, D),\n",
    "        embedding,\n",
    "        metric=metric\n",
    "    ).reshape(V)\n",
    "\n",
    "    idxs = distances.argsort()[1:n+1]\n",
    "\n",
    "    print(\"Neighbors of:\", w)\n",
    "    for idx in idxs:\n",
    "        print(\"\\t\", idx2word[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace7d44",
   "metadata": {},
   "source": [
    "# GloVe 50D Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd79b7",
   "metadata": {},
   "source": [
    "# Load GloVe 50D Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae71fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe 50D word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading GloVe 50D word vectors...\")\n",
    "\n",
    "word2vec = {}\n",
    "embedding = []\n",
    "idx2word = []\n",
    "\n",
    "with open(\n",
    "    r\"C:\\Users\\gasse\\OneDrive\\Desktop\\archive1\\glove.6B.50d.txt\",\n",
    "    encoding=\"utf-8\"\n",
    ") as f:\n",
    "\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype=\"float32\")\n",
    "\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "\n",
    "embedding = np.array(embedding)\n",
    "V, D = embedding.shape\n",
    "\n",
    "print(\"Found %s word vectors.\" % V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771b0c2",
   "metadata": {},
   "source": [
    "# Inspect Vocabulary & Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4540405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: the, Vector sample: [ 0.418       0.24968    -0.41242     0.1217      0.34527    -0.044457\n",
      " -0.49688    -0.17862    -0.00066023 -0.6566    ]\n",
      "Word: ,, Vector sample: [ 0.013441  0.23682  -0.16899   0.40951   0.63812   0.47709  -0.42852\n",
      " -0.55641  -0.364    -0.23938 ]\n",
      "Word: ., Vector sample: [ 0.15164  0.30177 -0.16763  0.17684  0.31719  0.33973 -0.43478 -0.31086\n",
      " -0.44999 -0.29486]\n",
      "Word: of, Vector sample: [ 0.70853  0.57088 -0.4716   0.18048  0.54449  0.72603  0.18157 -0.52393\n",
      "  0.10381 -0.17566]\n",
      "Word: to, Vector sample: [ 0.68047  -0.039263  0.30186  -0.17792   0.42962   0.032246 -0.41376\n",
      "  0.13228  -0.29847  -0.085253]\n",
      "Word: and, Vector sample: [ 0.26818   0.14346  -0.27877   0.016257  0.11384   0.69923  -0.51332\n",
      " -0.47368  -0.33075  -0.13834 ]\n",
      "Word: in, Vector sample: [ 0.33042   0.24995  -0.60874   0.10923   0.036372  0.151    -0.55083\n",
      " -0.074239 -0.092307 -0.32821 ]\n",
      "Word: a, Vector sample: [ 0.21705  0.46515 -0.46757  0.10082  1.0135   0.74845 -0.53104 -0.26256\n",
      "  0.16812  0.13182]\n",
      "Word: \", Vector sample: [ 0.25769   0.45629  -0.76974  -0.37679   0.59272  -0.063527  0.20545\n",
      " -0.57385  -0.29009  -0.13662 ]\n",
      "Word: 's, Vector sample: [ 0.23727  0.40478 -0.20547  0.58805  0.65533  0.32867 -0.81964 -0.23236\n",
      "  0.27428  0.24265]\n",
      "Word: for, Vector sample: [ 0.15272   0.36181  -0.22168   0.066051  0.13029   0.37075  -0.75874\n",
      " -0.44722   0.22563   0.10208 ]\n",
      "Word: -, Vector sample: [-0.16768  1.2151   0.49515  0.26836 -0.4585  -0.23311 -0.52822 -1.3557\n",
      "  0.16098  0.37691]\n",
      "Word: that, Vector sample: [ 0.88387  -0.14199   0.13566   0.098682  0.51218   0.49138  -0.47155\n",
      " -0.30742   0.01963   0.12686 ]\n",
      "Word: on, Vector sample: [ 0.30045   0.25006  -0.16692   0.1923    0.026921 -0.079486 -0.91383\n",
      " -0.1974   -0.053413 -0.40846 ]\n",
      "Word: is, Vector sample: [ 0.6185     0.64254   -0.46552    0.3757     0.74838    0.53739\n",
      "  0.0022239 -0.60577    0.26408    0.11703  ]\n",
      "Word: was, Vector sample: [ 0.086888 -0.19416  -0.24267  -0.33391   0.56731   0.39783  -0.97809\n",
      "  0.03159  -0.61469  -0.31406 ]\n",
      "Word: said, Vector sample: [ 0.38973 -0.2121   0.51837  0.80136  1.0336  -0.27784 -0.84525 -0.25333\n",
      "  0.12586 -0.90342]\n",
      "Word: with, Vector sample: [ 0.25616   0.43694  -0.11889   0.20345   0.41959   0.85863  -0.60344\n",
      " -0.31835  -0.6718    0.003984]\n",
      "Word: he, Vector sample: [-0.20092  -0.060271 -0.61766  -0.8444    0.5781    0.14671  -0.86098\n",
      "  0.6705   -0.86556  -0.18234 ]\n",
      "Word: as, Vector sample: [ 0.20782  0.12713 -0.30188 -0.23125  0.30175  0.33194 -0.52776 -0.44042\n",
      " -0.48348  0.03502]\n",
      "[ 0.418       0.24968    -0.41242     0.1217      0.34527    -0.044457\n",
      " -0.49688    -0.17862    -0.00066023 -0.6566    ]\n",
      "-------------------------------\n",
      "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\", 'for', '-', 'that', 'on', 'is', 'was', 'said', 'with', 'he', 'as']\n",
      "-------------------------------\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "for i, (word, vec) in enumerate(word2vec.items()):\n",
    "    if i == 20:\n",
    "        break\n",
    "    print(f\"Word: {word}, Vector sample: {vec[:10]}\")\n",
    "\n",
    "print (embedding[0][:10])\n",
    "print ('-------------------------------')\n",
    "print (idx2word[:20])\n",
    "print ('-------------------------------')\n",
    "print (len(embedding[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fd61f",
   "metadata": {},
   "source": [
    "# Analogy Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633a36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king - man = queen - woman\n",
      "None\n",
      "-------------------------------\n",
      "france - paris = britain - london\n",
      "None\n",
      "-------------------------------\n",
      "japan - japanese = china - chinese\n",
      "None\n",
      "-------------------------------\n",
      "man - woman = father - mother\n",
      "None\n",
      "-------------------------------\n",
      "cairo - egypt = damascus - syria\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (find_analogies_fast(\"king\", \"man\", \"woman\"))\n",
    "print ('-------------------------------')\n",
    "print (find_analogies_fast(\"france\", \"paris\", \"london\"))\n",
    "print ('-------------------------------')\n",
    "print (find_analogies_fast(\"japan\", \"japanese\", \"chinese\"))\n",
    "print ('-------------------------------')\n",
    "print (find_analogies_fast(\"man\", \"woman\", \"mother\"))\n",
    "print ('-------------------------------')\n",
    "print (find_analogies_fast(\"cairo\", \"egypt\", \"syria\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e4df38",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09597c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of: king\n",
      "\t prince\n",
      "\t queen\n",
      "\t ii\n",
      "\t emperor\n",
      "\t son\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: france\n",
      "\t french\n",
      "\t belgium\n",
      "\t paris\n",
      "\t spain\n",
      "\t netherlands\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: einstein\n",
      "\t relativity\n",
      "\t bohr\n",
      "\t physics\n",
      "\t heisenberg\n",
      "\t freud\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: woman\n",
      "\t girl\n",
      "\t man\n",
      "\t mother\n",
      "\t her\n",
      "\t boy\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: february\n",
      "\t october\n",
      "\t december\n",
      "\t january\n",
      "\t august\n",
      "\t september\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (nearest_neighbors(\"king\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"france\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"einstein\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"woman\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"february\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2792086",
   "metadata": {},
   "source": [
    "# GloVe 300D Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d88fd0",
   "metadata": {},
   "source": [
    "# Load GloVe 300D Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ecf3270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe 300D word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading GloVe 300D word vectors...\")\n",
    "\n",
    "word2vec = {}\n",
    "embedding = []\n",
    "idx2word = []\n",
    "\n",
    "with open(\n",
    "    r\"C:\\Users\\gasse\\OneDrive\\Desktop\\archive\\glove.6B.300d.txt\",\n",
    "    encoding=\"utf-8\"\n",
    ") as f:\n",
    "\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype=\"float32\")\n",
    "\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "\n",
    "embedding = np.array(embedding)\n",
    "V, D = embedding.shape\n",
    "\n",
    "print(\"Found %s word vectors.\" % V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17055737",
   "metadata": {},
   "source": [
    "# Analogy Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "023303e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king - man = queen - woman\n",
      "None\n",
      "-------------------------------\n",
      "france - paris = italy - rome\n",
      "None\n",
      "-------------------------------\n",
      "japan - japanese = italy - italian\n",
      "None\n",
      "-------------------------------\n",
      "heir - heiress = prince - princess\n",
      "None\n",
      "-------------------------------\n",
      "nephew - niece = uncle - aunt\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (find_analogies_fast(\"king\", \"man\", \"woman\"))\n",
    "print ('-------------------------------')\n",
    "print (find_analogies_fast(\"france\", \"paris\", \"rome\"))\n",
    "print ('-------------------------------')\n",
    "print (find_analogies_fast(\"japan\", \"japanese\", \"italian\"))\n",
    "print ('-------------------------------')\n",
    "print (find_analogies_fast(\"heir\", \"heiress\", \"princess\"))\n",
    "print ('-------------------------------')\n",
    "print (find_analogies_fast(\"nephew\", \"niece\", \"aunt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3bc1b9",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd2c93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of: king\n",
      "\t queen\n",
      "\t prince\n",
      "\t monarch\n",
      "\t kingdom\n",
      "\t throne\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: france\n",
      "\t french\n",
      "\t paris\n",
      "\t belgium\n",
      "\t spain\n",
      "\t italy\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: japan\n",
      "\t japanese\n",
      "\t tokyo\n",
      "\t korea\n",
      "\t china\n",
      "\t asia\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: woman\n",
      "\t girl\n",
      "\t man\n",
      "\t mother\n",
      "\t she\n",
      "\t her\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: rome\n",
      "\t italy\n",
      "\t naples\n",
      "\t turin\n",
      "\t venice\n",
      "\t roman\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: bolt\n",
      "\t usain\n",
      "\t locking\n",
      "\t crossbow\n",
      "\t bolts\n",
      "\t asafa\n",
      "None\n",
      "-------------------------------\n",
      "Neighbors of: hello\n",
      "\t goodbye\n",
      "\t hey\n",
      "\t !\n",
      "\t dolly\n",
      "\t muddah\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (nearest_neighbors(\"king\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"france\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"japan\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"woman\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"rome\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"bolt\"))\n",
    "print ('-------------------------------')\n",
    "print (nearest_neighbors(\"hello\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
